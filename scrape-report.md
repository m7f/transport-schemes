### Сбор данных

Для сбора информации о маршрутах и станциях Санкт-Петербурга
я остановился на [государственном сайте](http://transport.orgp.spb.ru) города.

При переходе к случайному маршруту, в разделе XHR я обнаружил JSON-файл, содержащий всю необходимую информацию.
Единственный его недостаток был в том, что маршрут сочетал в себе соединенные прямой и обратный.
Пометки о направлении отсутствовали и было непонятно, где заканчивался прямой маршрут и начинался обратный.
На этой же странице присутствовала таблица с остановками, где они разделялись на две части. Доступа к таблице
через HTML не было - она подгружалась извне. Помогла ссылка на расписание - там таблица уже отслеживалась.
Я извлек с этой страницы длины прямого и обратного маршрутов: этого было достаточно. Теперь нужно было
найти список всех id, чтобы проитерироваться по всем маршрутам.

При сборе id возникла проблема. Было понятно, где хранится весь список id, но здесь не поддерживался метод GET.
То есть, оттуда нельзя было так легко достать данные, как в предыдущем случае.
Все, что было доступно - JSON-файл с 25 остановками для предпросмотра.
Я увеличил число показываемых остановок в таблице до 100 и вручную скопировал пять JSON файлов с каждой страницы,
сохранив в директории scraper/id_data, после чего извлек из каждого все id и сохранил их в общий JSON-файл.

С остановками так сделать не получилось, так как их было слишком много. Пришлось обойти каждый сохраненный маршрут
и извлечь из них остановки, собирая их все вместе. Поскольку итоговый формат был именно JSON,
повторяющиеся станции исчезли. Вместе с id я сразу сохранил координаты и названия в нужном формате, как требовалось в шаблоне.
Названия остановок, содержащие кавычки, пришлось подредактировать: неэкранированные кавычки вызывали ошибку в чтении формата.

Данные были собраны и представлены в нужном формате.
